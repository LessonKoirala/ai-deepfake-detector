AI Deepfake Detector

## ğŸ” Overview

This system provides a dual-model approach to digital media authentication:

- **Image Classification**: Detects AI-generated images vs. human-created content

- **Video Analysis**: Identifies deepfake videos through frame-by-frame processing



The pipeline includes workflow support from data preprocessing to model deployment with a RESTful API interface.


## âœ¨ Features

- **Video Preprocessing**: Converts video datasets into sequential image frames for model training

- **Dual-Model Architecture**: Separate specialised models for image and video analysis

- **RESTful API**: Flask-based endpoints for real-time media analysis

- **Web Interface**: User-friendly frontend for testing and demonstration

- **Model Management**: Organised storage for trained models, training logs, and metadata

- **Reproducibility**: Complete training pipeline with configurable parameters



## ğŸ“ Project Structure



```

.

â”œâ”€â”€ app.pyÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Main Flask application

â”œâ”€â”€ cleanvideo.pyÂ  Â  Â  Â  Â  Â  Â  Â # Video preprocessing script

â”œâ”€â”€ image_train.pyÂ  Â  Â  Â  Â  Â  Â  # Image classification model training

â”œâ”€â”€ train_video.pyÂ  Â  Â  Â  Â  Â  Â  # Deepfake video model training

â”œâ”€â”€ deepfake_detector_model.kerasÂ  # Trained video analysis model

â”œâ”€â”€ image_model_output/Â  Â  Â  Â  Â # Trained models and metadata

â”‚Â  Â â”œâ”€â”€ ai_vs_human.keras

â”‚Â  Â â”œâ”€â”€ audio_model.h5

â”‚Â  Â â”œâ”€â”€ fake_real_detector.keras

â”‚Â  Â â””â”€â”€ training_metadata.json

â”œâ”€â”€ image_logs/Â  Â  Â  Â  Â  Â  Â  Â  Â # Training logs and checkpoints

â”‚Â  Â â””â”€â”€ 20250818_105521/

â”‚Â  Â  Â  Â â”œâ”€â”€ train/

â”‚Â  Â  Â  Â â””â”€â”€ validation/

â”œâ”€â”€ processed_image_data/Â  Â  Â  Â # Preprocessed image frames

â”‚Â  Â â”œâ”€â”€ ai/

â”‚Â  Â â””â”€â”€ real/

â”œâ”€â”€ templates/

â”‚Â  Â â””â”€â”€ index.htmlÂ  Â  Â  Â  Â  Â  Â # Web interface

â”œâ”€â”€ uploads/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Temporary file storage

â”œâ”€â”€ archive (1)/Â  Â  Â  Â  Â  Â  Â  # Raw image dataset

â”‚Â  Â â”œâ”€â”€ test/

â”‚Â  Â â””â”€â”€ train/

â””â”€â”€ videodata/Â  Â  Â  Â  Â  Â  Â  Â  # Raw video dataset

Â  Â  â”œâ”€â”€ ai/

Â  Â  â””â”€â”€ real/

```



## ğŸ› ï¸ Prerequisites



- **Python 3.8+**

- **pip** (Python package manager)

- Recommended: Virtual environment (venv or conda)



## âš¡ Quick Start



### Installation



1. **Clone the Repository**

Â  Â ```bash

Â  Â git clone https://github.com/your-username/ai-deepfake-detector.git

Â  Â cd ai-deepfake-detector

Â  Â ```



2. **Install Dependencies**

Â  Â ```bash

Â  Â pip install Flask Flask-Cors numpy tensorflow Pillow opencv-python

Â  Â ```



### Dataset Preparation



1. **Image Dataset**: Place your image classification dataset in `archive (1)/` with `test/` and `train/` subdirectories

2. **Video Dataset**: Organise video files in `videodata/` with `ai/` and `real/` subfolders



### Model Training Pipeline



1. **Preprocess Video Data**

Â  Â ```bash

Â  Â python cleanvideo.py

Â  Â ```

Â  Â *Converts videos to image frames in `processed_image_data/`*



2. **Train Image Classification Model**

Â  Â ```bash

Â  Â python image_train.py

Â  Â ```

Â  Â *Generates `image_model_output/ai_vs_human.keras` and `class_names.json`*



3. **Train Deepfake Detection Model**

Â  Â ```bash

Â  Â python train_video.py

Â  Â ```

Â  Â *Produces `deepfake_detector_model.keras` in project root*



### Deployment



1. **Start the API Server**

Â  Â ```bash

Â  Â python app.py

Â  Â ```



2. **Access the Application**

Â  Â - API: `http://0.0.0.0:5001`

Â  Â - Web Interface: `http://0.0.0.0:5001/`



## ğŸŒ API Endpoints



| Endpoint | Method | Description | Parameters |

|----------|--------|-------------|------------|

| `/` | GET | Serves web interface | - |

| `/analyse/image` | POST | Analyses uploaded image | `file`: image file (multipart/form-data) |

| `/analyse/video` | POST | Analyses uploaded video | `file`: video file (multipart/form-data) |

| `/model/status` | GET | Returns model loading status and versions | - |



### Example API Response



```json

{

Â  "prediction": "AI-generated",

Â  "confidence": 0.92,

Â  "model_version": "1.0.0"

}

```



## ğŸš€ Usage Examples



### Analyse Image via curl

```bash

curl -X POST -F "file=@test_image.jpg" http://localhost:5001/analyze/image

```



### Analyse Video via curl

```bash

curl -X POST -F "file=@test_video.mp4" http://localhost:5001/analyze/video

```



## ğŸ“Š Model Architecture



- **Image Model**: Custom CNN architecture trained on diverse image datasets

- **Video Model**: Two-stage fine-tuning process using temporal features from video frames

- **Input Processing**: Standardised preprocessing pipeline for consistent analysis



## ğŸ”§ Configuration



Training parameters and model configurations can be modified in the respective training scripts:

- `image_train.py`: Image model hyperparameters

- `train_video.py`: Video training pipeline settings

- Metadata stored in `training_metadata.json` for reproducibility



1. Fork the repository

2. Create a feature branch (`git checkout -b feature/amazing-feature`)

3. Commit your changes (`git commit -m 'Add amazing feature'`)

4. Push to the branch (`git push origin feature/amazing-feature`)

5. Open a Pull Request
